{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68599174",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'masks.iypnb'; 'masks' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01miypnb\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NUM_CLASSES, DEVICE, SATELLITE_FOLDER, MASK_FOLDER, MODEL_PATH, GCN\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Define a color palette for the classes (you can adjust these colors as needed)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m CLASS_COLORS \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     13\u001b[0m     [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m],       \u001b[38;5;66;03m# Class 0: Black (background or empty)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     [\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m],     \u001b[38;5;66;03m# Class 1: Red\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     [\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m]    \u001b[38;5;66;03m# Class 4: Yellow\u001b[39;00m\n\u001b[1;32m     18\u001b[0m ]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'masks.iypnb'; 'masks' is not a package"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from skimage.segmentation import slic\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from masks import NUM_CLASSES, DEVICE, SATELLITE_FOLDER, MASK_FOLDER, MODEL_PATH, GCN\n",
    "# Define a color palette for the classes (you can adjust these colors as needed)\n",
    "CLASS_COLORS = [\n",
    "    [0, 0, 0],       # Class 0: Black (background or empty)\n",
    "    [255, 0, 0],     # Class 1: Red\n",
    "    [0, 255, 0],     # Class 2: Green\n",
    "    [0, 0, 255],     # Class 3: Blue\n",
    "    [255, 255, 0]    # Class 4: Yellow\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7122a3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_data(image_path):\n",
    "    # Load satellite image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Segment satellite image into superpixels\n",
    "    segments = slic(image, n_segments=100, compactness=10, start_label=1)\n",
    "    \n",
    "    # Generate node features (average color of each superpixel)\n",
    "    node_features = []\n",
    "    unique_segments = np.unique(segments)\n",
    "\n",
    "    for segment in unique_segments:\n",
    "        mask_segment = segments == segment\n",
    "        avg_color = image[mask_segment].mean(axis=0)\n",
    "        node_features.append(avg_color)\n",
    "    \n",
    "    # Convert to PyTorch tensor\n",
    "    node_features = torch.tensor(np.array(node_features), dtype=torch.float32).to(DEVICE)\n",
    "    \n",
    "    # Generate simple edge connections (adjacent superpixels)\n",
    "    edges = [[i, i + 1] for i in range(len(unique_segments) - 1)]\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous().to(DEVICE)\n",
    "\n",
    "    # Create the graph data object\n",
    "    data = Data(x=node_features, edge_index=edge_index)\n",
    "    data.segments = segments  # Optional: useful if you want to map predictions back to the original image shape\n",
    "    return data\n",
    "\n",
    "# Load the trained model from a checkpoint\n",
    "def load_checkpoint(path, model):\n",
    "    if os.path.exists(path):\n",
    "        checkpoint = torch.load(path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(f\"Checkpoint loaded from: {path}.\")\n",
    "        return model\n",
    "    else:\n",
    "        print(f\"No checkpoint found at: {path}.\")\n",
    "        return model\n",
    "\n",
    "# Predict using the trained GCN model\n",
    "def predict(model, satellite_image_path):\n",
    "    model.eval()\n",
    "    # Preprocess the image into a graph\n",
    "    data = preprocess_data(satellite_image_path)\n",
    "    \n",
    "    # Forward pass through the model\n",
    "    with torch.no_grad():\n",
    "        output = model(data.x, data.edge_index)\n",
    "        predictions = output.argmax(dim=1)  # Choose the class with the highest probability for each node\n",
    "\n",
    "    return predictions, data.segments\n",
    "\n",
    "\n",
    "# Define a color palette for the classes (you can adjust these colors as needed)\n",
    "CLASS_COLORS = [\n",
    "    [0, 0, 0],       # Class 0: Black (background or empty)\n",
    "    [255, 0, 0],     # Class 1: Red\n",
    "    [0, 255, 0],     # Class 2: Green\n",
    "    [0, 0, 255],     # Class 3: Blue\n",
    "    [255, 255, 0]    # Class 4: Yellow\n",
    "]\n",
    "\n",
    "\n",
    "def save_predictions(image_path, predictions, segments, output_folder, alpha=0.5):\n",
    "    # Ensure the output folder exists\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Read the input image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Prepare the prediction map and segmented image\n",
    "    segmented_image = np.zeros_like(image)\n",
    "    prediction_map = np.zeros_like(segments)\n",
    "    \n",
    "    # Loop through each unique segment\n",
    "    unique_segments = np.unique(segments)\n",
    "    for i, segment in enumerate(unique_segments):\n",
    "        mask_segment = segments == segment\n",
    "        predicted_class = predictions[i].item()  # Get the predicted class for the superpixel\n",
    "        \n",
    "        # Assign the predicted class to the corresponding pixels in the prediction map\n",
    "        prediction_map[mask_segment] = predicted_class\n",
    "\n",
    "        # Assign the color corresponding to the predicted class (using the CLASS_COLORS dictionary)\n",
    "        color = CLASS_COLORS[predicted_class]  # Get the color for the predicted class\n",
    "        segmented_image[mask_segment] = color  # Apply the color to the segment\n",
    "    \n",
    "    # Prepare the transparent overlay (blend the original image with the prediction)\n",
    "    blended_image = cv2.addWeighted(image, 1 - alpha, segmented_image, alpha, 0)\n",
    "\n",
    "    # Prepare the file path for saving the output image\n",
    "    base_name = os.path.basename(image_path)\n",
    "    file_name, _ = os.path.splitext(base_name)\n",
    "    output_path = os.path.join(output_folder, f\"{file_name}_predicted.png\")\n",
    "\n",
    "    # Save the resulting image\n",
    "    cv2.imwrite(output_path, blended_image)\n",
    "    #print(f\"Prediction saved as: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27d4e9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from: ./gcn_roof_model.pth.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = GCN(in_channels=3, hidden_channels=16, out_channels=NUM_CLASSES).to(DEVICE)\n",
    "model = load_checkpoint(MODEL_PATH, model)\n",
    "\n",
    "# Process a set of images and make predictions\n",
    "satellite_images = sorted([f for f in os.listdir(SATELLITE_FOLDER) if f.lower().endswith('.png')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adf1dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 833/833 [04:39<00:00,  2.98it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for image_name in tqdm(satellite_images):\n",
    "    image_path = os.path.join(SATELLITE_FOLDER, image_name)\n",
    "    \n",
    "    # Make prediction\n",
    "    predictions, segments = predict(model, image_path)\n",
    "    \n",
    "    # Visualize the results\n",
    "    save_predictions(image_path, predictions, segments, \"./images2/val_outputs/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
